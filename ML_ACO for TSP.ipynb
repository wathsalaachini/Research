{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376674bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docplex.mp.model import Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from numpy.random import choice as np_choice\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "#------------------------------------------Solve 100 TSP instances using CPLEX-------------------------------------------\n",
    "def solve_tsp_cplex(distance_matrix):\n",
    "    n = len(distance_matrix)                  #n = 30\n",
    "    mdl = Model(name=\"TSP_CPLEX\")\n",
    "    x = [[mdl.binary_var(name=f\"x_{i}_{j}\") for j in range(n)] for i in range(n)]              # Decision variables\n",
    "    u = [mdl.continuous_var(name=f\"u_{i}\", lb=1, ub=n) for i in range(n)]                      \n",
    "    mdl.minimize(mdl.sum(distance_matrix[i][j] * x[i][j] for i in range(n) for j in range(n) if i != j)) # Objective function\n",
    "    # Constraints: Each city must have exactly one incoming and one outgoing edge\n",
    "    for j in range(n):\n",
    "        mdl.add_constraint(mdl.sum(x[i][j] for i in range(n) if i != j) == 1)\n",
    "    for i in range(n):\n",
    "        mdl.add_constraint(mdl.sum(x[i][j] for j in range(n) if i != j) == 1)   \n",
    "    for i in range(1, n):                                                                     # Subtour elimination (MTZ formulation)\n",
    "        for j in range(1, n):\n",
    "            if i != j:\n",
    "                mdl.add_constraint(u[i] - u[j] + n * x[i][j] <= n - 1)\n",
    "    solution = mdl.solve()                                                                    # Solve model\n",
    "    if solution:\n",
    "        print(\"\\nDecision Variable Values (x[i][j])\")\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j:\n",
    "                    value = x[i][j].solution_value  \n",
    "                    print(f\"x[{i}][{j}] = {value:.2f}\")  \n",
    "    if solution:\n",
    "        # Extract the optimal route \n",
    "        optimal_edges = [(i, j) for i in range(n) for j in range(n) if i != j and x[i][j].solution_value > 0.5]\n",
    "        return optimal_edges, solution.objective_value\n",
    "    else:\n",
    "        return [], float('inf')\n",
    "#-----------------------------create 100 instances with 30 cities-------------------------------------------------------\n",
    "random = np.random\n",
    "random.seed(1)  \n",
    "num_instances = 100 \n",
    "n_small_cities = 30  \n",
    "instance_results = []\n",
    "for instance in range(num_instances):\n",
    "    distance_matrix = np.random.rand(n_small_cities, n_small_cities) * 100             # Generate a random distance matrix\n",
    "    np.fill_diagonal(distance_matrix, 0)\n",
    "    distance_matrix = np.round(distance_matrix, 2)     \n",
    "    optimal_edges, cost = solve_tsp_cplex(distance_matrix)                             # Solve the TSP problem using CPLEX\n",
    "    instance_results.append((instance + 1, optimal_edges, cost, distance_matrix)) \n",
    "    print(f\"\\nProblem {instance + 1}:\")\n",
    "    print(f\"Optimal Edges: {optimal_edges}\")\n",
    "    print(f\"Total Cost: {cost:.2f}\")\n",
    "print(\"\\n--- Distance Matrix for Instance 1 ---\")\n",
    "distance_matrix_instance_1 = instance_results[0][3]  \n",
    "print(distance_matrix_instance_1)\n",
    "#-----------------------------------------Label edges as 1/-1---------------------------------------------------------\n",
    "data =[]\n",
    "for instance_id, optimal_edges, cost, distance_matrix in instance_results:              # generate labeled edges\n",
    "    n = len(distance_matrix)\n",
    "    optimal_set = set(optimal_edges)                                                    #quick lookup\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                edge = (i, j)   \n",
    "                if edge in optimal_set:                                                  # Assign labels\n",
    "                    label = 1  # Optimal path\n",
    "                else:\n",
    "                    label = -1  # Non-optimal path\n",
    "                data.append((instance_id, edge, label))\n",
    "df_label_edges = pd.DataFrame(data, columns=[\"Instance\", \"Edge\", \"label\"])\n",
    "#-----------------------------------Compute f1, f2, f3, f4 scores for all edges----------------------------------------------\n",
    "def compute_graph_features(instance_num, distance_matrix):\n",
    "    n = len(distance_matrix)            \n",
    "    f1_values, f2_values, f3_values, f4_values = {}, {}, {}, {}\n",
    "    for i in range(n):\n",
    "        min_cik = np.min(distance_matrix[i, :])\n",
    "        max_cik = np.max(distance_matrix[i, :])\n",
    "        avg_cik = np.mean(distance_matrix[i, :])\n",
    "        for j in range(n):  \n",
    "            if i != j:\n",
    "                key = (instance_num, (i, j))\n",
    "                if max_cik - min_cik != 0:\n",
    "                    f1_values[key] = np.round((distance_matrix[i, j] - min_cik) / (max_cik - min_cik),3)\n",
    "                else:\n",
    "                    f1_values[key] = 0\n",
    "    for j in range(n):\n",
    "        min_c_kj = np.min(distance_matrix[:, j])\n",
    "        max_c_kj = np.max(distance_matrix[:, j])\n",
    "        avg_c_kj = np.mean(distance_matrix[:, j])\n",
    "        for i in range(n):  \n",
    "            if i != j:\n",
    "                key = (instance_num, (i, j))\n",
    "                if max_c_kj - min_c_kj != 0:\n",
    "                    f2_values[key] = np.round((distance_matrix[i, j] - min_c_kj) / (max_c_kj - min_c_kj),3)\n",
    "                    f3_values[key] = np.round((distance_matrix[i, j] - avg_cik) / (max_c_kj - min_c_kj),3)\n",
    "                    f4_values[key] = np.round((distance_matrix[i, j] - avg_c_kj) / (max_c_kj - min_c_kj),3)\n",
    "                else:\n",
    "                    f2_values[key] = f3_values[key] = f4_values[key] = 0\n",
    "    return f1_values, f2_values, f3_values, f4_values\n",
    "f1_scores, f2_scores, f3_scores, f4_scores = {}, {}, {}, {}                                  # Compute features for all instances\n",
    "for instance_num, _, _, distance_matrix in instance_results:\n",
    "    f1, f2, f3, f4 = compute_graph_features(instance_num, distance_matrix)\n",
    "    f1_scores.update(f1)\n",
    "    f2_scores.update(f2)\n",
    "    f3_scores.update(f3)\n",
    "    f4_scores.update(f4)\n",
    "f1_df = pd.DataFrame(f1_scores.items(), columns=[\"Instance_Edge\", \"f1\"])\n",
    "f2_df = pd.DataFrame(f2_scores.items(), columns=[\"Instance_Edge\", \"f2\"])\n",
    "f3_df = pd.DataFrame(f3_scores.items(), columns=[\"Instance_Edge\", \"f3\"])\n",
    "f4_df = pd.DataFrame(f4_scores.items(), columns=[\"Instance_Edge\", \"f4\"])\n",
    "for df in [f1_df, f2_df, f3_df, f4_df]:                                                    # Extract instance and edge columns\n",
    "    df[['Instance', 'Edge']] = pd.DataFrame(df['Instance_Edge'].tolist(), index=df.index)\n",
    "    df.drop(columns=[\"Instance_Edge\"], inplace=True)\n",
    "final_features_df = f1_df.merge(f2_df, on=['Instance', 'Edge'])                            # Merge all feature DataFrames into one\n",
    "final_features_df = final_features_df.merge(f3_df, on=['Instance', 'Edge'])\n",
    "final_features_df = final_features_df.merge(f4_df, on=['Instance', 'Edge'])                # Merge feature dataset with edge labels\n",
    "combined_df = final_features_df.merge(df_label_edges, on=['Instance', 'Edge'], how='inner')\n",
    "combined_df.to_csv(\"Desktop/features_TSP.csv\", index=False)\n",
    "#------------------------------------------Train the SVM model---------------------------------------------------\n",
    "df = pd.read_csv(\"Desktop/features_TSP.csv\")                                              # Extract features and labels                                                            \n",
    "X = df[['f1', 'f2', 'f3', 'f4']]                                                          # Feature columns\n",
    "y = df['label']                                                                           # Target labels \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "svm_1 = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm_1.fit(X_train, y_train)\n",
    "y_pred = svm_1.predict(X_test)                                       \n",
    "accuracy = accuracy_score(y_test, y_pred)                                                 # Evaluate the model\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "#----------------------------------------------penalize misclassifying----------------------------------------\n",
    "n = len(y_train)                                                                          # Compute class weights\n",
    "n_pos = (y_train == 1).sum()                                                              # Number of positive points\n",
    "n_neg = (y_train == -1).sum()                                                             # Number of negative points\n",
    "class_weights = {\n",
    "    -1: 1,                                                                                # r (negative points)\n",
    "    1: n_neg / n_pos                                                                      # r+ (positive points)\n",
    "}\n",
    "svm_2 = SVC(kernel='linear', probability=True, class_weight=class_weights, random_state=42)# Train an SVM model with class weights\n",
    "svm_2.fit(X_train, y_train)\n",
    "y_pred_2= svm_2.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred_2)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")                                                  # for test set\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_2))\n",
    "#------------------------------------- Extract weight vector (w) and bias (b)-------------------------------------------\n",
    "w = svm_2.coef_[0]   \n",
    "b = svm_2.intercept_[0]  \n",
    "print(\"Extracted Model Parameters:\")\n",
    "print(f\"Weight Vector (w): {w}\")\n",
    "print(f\"Bias (b): {b}\")\n",
    "#------------------------------------- Generate the new unseen instance------------------------------------------------------\n",
    "np.random.seed(42)\n",
    "num_instances_test = 1 \n",
    "n_cities_test = 100  \n",
    "distance_matrices_test = []\n",
    "for instance in range(num_instances_test):\n",
    "    distance_matrix_test = np.random.rand(n_cities_test, n_cities_test) * 100      \n",
    "    np.fill_diagonal(distance_matrix_test, 0)\n",
    "    distance_matrix_test = np.round(distance_matrix_test, 2)\n",
    "    distance_matrices_test.append((instance + 1, distance_matrix_test)) \n",
    "print(\"\\n--- Distance Matrix for new unseen instance ---\") \n",
    "print(print(distance_matrices_test[0][1]))\n",
    "#-----------------------------------Compute f1, f2, f3 scores for all edges in new unseen instance----------------------------------------------\n",
    "f1_scores, f2_scores, f3_scores, f4_scores = {}, {}, {}, {}\n",
    "for num_instances_test, distance_matrix_test in distance_matrices_test:\n",
    "    f1, f2, f3, f4 = compute_graph_features(num_instances_test, distance_matrix_test)\n",
    "    f1_scores.update(f1)\n",
    "    f2_scores.update(f2)\n",
    "    f3_scores.update(f3)\n",
    "    f4_scores.update(f4)\n",
    "f1_df = pd.DataFrame(f1_scores.items(), columns=[\"Instance_Edge\", \"f1\"])\n",
    "f2_df = pd.DataFrame(f2_scores.items(), columns=[\"Instance_Edge\", \"f2\"])\n",
    "f3_df = pd.DataFrame(f3_scores.items(), columns=[\"Instance_Edge\", \"f3\"])\n",
    "f4_df = pd.DataFrame(f4_scores.items(), columns=[\"Instance_Edge\", \"f4\"])\n",
    "for df in [f1_df, f2_df, f3_df, f4_df]:                                                     # Extract instance and edge columns\n",
    "    df[['Instance', 'Edge']] = pd.DataFrame(df['Instance_Edge'].tolist(), index=df.index)\n",
    "    df.drop(columns=[\"Instance_Edge\"], inplace=True)\n",
    "final_features_df = f1_df.merge(f2_df, on=['Instance', 'Edge'])\n",
    "final_features_df = final_features_df.merge(f3_df, on=['Instance', 'Edge'])\n",
    "final_features_df = final_features_df.merge(f4_df, on=['Instance', 'Edge'])\n",
    "f_test = final_features_df[['f1', 'f2', 'f3', 'f4']].values \n",
    "w_column = w.reshape(-1, 1)  \n",
    "#-------------------------------------Compute Z scalars------------------------------------------------------\n",
    "z_values = np.dot(f_test,w_column) + b                                                      # (z = f_test * w^T + b) \n",
    "#------------------------------------- Compute predicted probability values for all edges in test instance-------------------------------------\n",
    "p_values = 1 / (1 + np.exp(-z_values))                                                      # sigmoid function (p = 1 / (1 + e^(-z)))\n",
    "z_values = z_values.flatten()\n",
    "p_values = p_values.flatten()\n",
    "p_values_df = pd.DataFrame({\n",
    "    'Instance': final_features_df['Instance'].values,  \n",
    "    'Edge': final_features_df['Edge'].values,  \n",
    "    'p': p_values  \n",
    "})\n",
    "z_p_df = pd.DataFrame({                                                                     # Create a DataFrame with computed z and p values\n",
    "    'Instance': final_features_df['Instance'],\n",
    "    'Edge': final_features_df['Edge'],\n",
    "    'z': z_values,\n",
    "    'p': p_values\n",
    "})\n",
    "final_features_df = final_features_df.drop(columns=['z', 'p'], errors='ignore')            # Ensure no duplicate z and p columns before merging\n",
    "final_combined_df = final_features_df[['Instance', 'Edge', 'f1', 'f2', 'f3', 'f4']].merge(\n",
    "    z_p_df, on=['Instance', 'Edge'], how='left'\n",
    ")\n",
    "final_combined_df.head()\n",
    "#----------------------------------------- Classical ACO algorithm for TSP-------------------------------------------------\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "class AntColony(object):\n",
    "    def __init__(self, distances, n_ants, n_best, iterations, decay, alpha=1, beta=1):\n",
    "        self.distances  = distances\n",
    "        self.pheromone = np.ones(self.distances.shape) / len(distances)\n",
    "        self.all_inds = range(len(distances))\n",
    "        self.n_ants = n_ants                                                   # Number of ants running per iteration                                    \n",
    "        self.n_best = n_best                                                   # Number of best ants who deposit pheromone\n",
    "        self.iterations = iterations\n",
    "        self.decay = decay                                                     # Rate it which pheromone decays\n",
    "        self.alpha = alpha                                                     # exponenet on pheromone\n",
    "        self.beta = beta                                                       # exponent on distance\n",
    "    def run(self):\n",
    "        shortest_path = None\n",
    "        all_time_shortest_path = (\"placeholder\", np.inf)\n",
    "        for i in range(self.iterations):\n",
    "            all_paths = self.gen_all_paths()\n",
    "            self.spread_pheronome(all_paths, self.n_best, shortest_path=shortest_path)\n",
    "            shortest_path = min(all_paths, key=lambda x: x[1])\n",
    "            print (shortest_path)\n",
    "            if shortest_path[1] < all_time_shortest_path[1]:\n",
    "                all_time_shortest_path = shortest_path            \n",
    "            self.pheromone = self.pheromone * self.decay            \n",
    "        return all_time_shortest_path\n",
    "    def spread_pheronome(self, all_paths, n_best, shortest_path):\n",
    "        sorted_paths = sorted(all_paths, key=lambda x: x[1])\n",
    "        for path, dist in sorted_paths[:n_best]:\n",
    "            for move in path:\n",
    "                self.pheromone[move] += 1.0 / self.distances[move]\n",
    "    def gen_path_dist(self, path):\n",
    "        total_dist = 0\n",
    "        for ele in path:\n",
    "            total_dist += self.distances[ele]\n",
    "        return total_dist\n",
    "    def gen_all_paths(self):\n",
    "        all_paths = []\n",
    "        for i in range(self.n_ants):\n",
    "            path = self.gen_path(0)\n",
    "            all_paths.append((path, self.gen_path_dist(path)))\n",
    "        return all_paths\n",
    "    def gen_path(self, start):\n",
    "        path = []\n",
    "        visited = set()\n",
    "        visited.add(start)\n",
    "        prev = start\n",
    "        for i in range(len(self.distances) - 1):\n",
    "            move = self.pick_move(self.pheromone[prev], self.distances[prev], visited)\n",
    "            path.append((prev, move))\n",
    "            prev = move\n",
    "            visited.add(move)\n",
    "        path.append((prev, start))   \n",
    "        return path\n",
    "    def pick_move(self, pheromone, dist, visited):\n",
    "        pheromone = np.copy(pheromone)\n",
    "        pheromone[list(visited)] = 0        \n",
    "        dist[dist == 0] = np.inf \n",
    "        probability = pheromone ** self.alpha * (( 1.0 / dist) ** self.beta)\n",
    "        norm_probability = probability / probability.sum()\n",
    "        move = np_choice(self.all_inds, 1, p=norm_probability)[0]\n",
    "        return move    \n",
    "ant_colony = AntColony(distance_matrix_test, 50, 1, 100, 0.95, alpha=1, beta=1)\n",
    "shortest_path = ant_colony.run()\n",
    "print (\"shorted_path: {}\".format(shortest_path))\n",
    "#---------------------------------------------Run time---------------------------------------------------------------------------\n",
    "\n",
    "start_time_classical_aco = time.time()                                      # Start time\n",
    "ant_colony = AntColony(distance_matrix_test, 50, 1, 100, 0.95, alpha=1, beta=1)\n",
    "shortest_path_classical_aco = ant_colony.run()\n",
    "end_time_classical_aco = time.time()  # End time\n",
    "runtime_classical_aco = end_time_classical_aco - start_time_classical_aco  # Calculate runtime\n",
    "print(f\"Classical ACO Runtime: {runtime_classical_aco:.4f} seconds\")\n",
    "\n",
    "#-------------------------------------------- Ml-ACO algorithm with extracting p_values-------------------------------------------\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "class AntColony_ML(object):\n",
    "    def __init__(self, distances, p_values_df, n_ants, n_best, iterations, decay, alpha=1, beta=1):\n",
    "        self.distances  = distances\n",
    "        self.pheromone = np.ones(self.distances.shape)/len(distances)\n",
    "        np.fill_diagonal(self.pheromone, 0)\n",
    "        self.all_inds = range(len(distances))\n",
    "        self.n_ants = n_ants\n",
    "        self.n_best = n_best\n",
    "        self.iterations = iterations\n",
    "        self.decay = decay\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.n_cities = len(distances)\n",
    "        self.p_values_df = p_values_df \n",
    "        self.p_values = self._extract_p_values()        \n",
    "    def run(self):\n",
    "        shortest_path = None\n",
    "        all_time_shortest_path = (\"placeholder\", np.inf)\n",
    "        for i in range(self.iterations):\n",
    "            all_paths = self.gen_all_paths()\n",
    "            self.spread_pheronome(all_paths, self.n_best, shortest_path=shortest_path)\n",
    "            shortest_path = min(all_paths, key=lambda x: x[1])\n",
    "            print (shortest_path)\n",
    "            if shortest_path[1] < all_time_shortest_path[1]:\n",
    "                all_time_shortest_path = shortest_path            \n",
    "            self.pheromone = self.pheromone * self.decay            \n",
    "        return all_time_shortest_path    \n",
    "    def _extract_p_values(self):\n",
    "        \"\"\"Convert DataFrame p_values into a matrix format\"\"\"\n",
    "        p_matrix = np.ones((self.n_cities, self.n_cities))  \n",
    "        np.fill_diagonal(p_matrix, 0)       \n",
    "        for _, row in self.p_values_df.iterrows():\n",
    "            i, j = row['Edge']\n",
    "            if i >= self.n_cities or j >= self.n_cities:  # Skip invalid edges\n",
    "                continue\n",
    "            p_matrix[i, j] = row['p']        \n",
    "        return p_matrix\n",
    "    def spread_pheronome(self, all_paths, n_best, shortest_path):\n",
    "        sorted_paths = sorted(all_paths, key=lambda x: x[1])\n",
    "        for path, dist in sorted_paths[:n_best]:\n",
    "            for move in path:\n",
    "                self.pheromone[move] += 1.0 / self.distances[move]\n",
    "    def gen_path_dist(self, path):\n",
    "        total_dist = 0\n",
    "        for ele in path:\n",
    "            total_dist += self.distances[ele]\n",
    "        return total_dist\n",
    "    def gen_all_paths(self):\n",
    "        all_paths = []\n",
    "        for i in range(self.n_ants):\n",
    "            path = self.gen_path(0)\n",
    "            all_paths.append((path, self.gen_path_dist(path)))\n",
    "        return all_paths\n",
    "    def gen_path(self, start):\n",
    "        path = []\n",
    "        visited = set()\n",
    "        visited.add(start)\n",
    "        prev = start\n",
    "        for i in range(len(self.distances) - 1):\n",
    "            move = self.pick_move(self.pheromone[prev], self.distances[prev],self.p_values[prev], visited)\n",
    "            path.append((prev, move))\n",
    "            prev = move\n",
    "            visited.add(move)\n",
    "        path.append((prev, start)) # going back to where we started    \n",
    "        return path\n",
    "    def pick_move(self, pheromone, dist,p_values, visited):\n",
    "        pheromone = np.copy(pheromone)\n",
    "        pheromone[list(visited)] = 0        \n",
    "        probability = (pheromone ** self.alpha) * ((p_values * (1.0 / dist)) ** self.beta)\n",
    "        norm_probability= probability / probability.sum()\n",
    "        move = np_choice(self.all_inds, 1, p=norm_probability)[0]\n",
    "        return move    \n",
    "ant_colony_ML = AntColony_ML(distance_matrix_test,p_values_df, 50, 1, 100, 0.95, alpha=1, beta=1)\n",
    "shortest_path = ant_colony_ML.run()\n",
    "print (\"shorted_path: {}\".format(shortest_path))\n",
    "#---------------------------------------------Run time---------------------------------------------------------------------------\n",
    "start_time_ml_aco = time.time()  # Start time\n",
    "ant_colony_ML = AntColony_ML(distance_matrix_test, p_values_df, 50, 1, 100, 0.95, alpha=1, beta=1)\n",
    "shortest_path_ml_aco = ant_colony_ML.run()\n",
    "end_time_ml_aco = time.time()  # End time\n",
    "runtime_ml_aco = end_time_ml_aco - start_time_ml_aco  # Calculate runtime\n",
    "print(f\"ML-enhanced ACO Runtime: {runtime_ml_aco:.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
